{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3c1d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import xarray as xr\n",
    "import torch\n",
    "from SphericConv import RegionalSphericalConv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_bands(data_tree, res):\n",
    "\n",
    "    res_key = f\"r{res}\"\n",
    "    bands = data_tree.measurements.reflectance[res_key]\n",
    "    return list(bands.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf80721",
   "metadata": {},
   "source": [
    "## **SphericalConv.**init**()**\n",
    "\n",
    "This is the constructor that sets up the spherical convolution layer for your regional HEALPix data. Unlike the original implementation that assumes a full sphere, this version works with only the HEALPix cells present in the dataset. It takes `available_cell_ids` (the cells that actually contain data in your geographic region) and the HEALPix resolution level. The constructor builds the neighbor relationships, creates efficient lookup tables, and initializes the underlying 1D convolution layer that will process the 3×3 patches. The key innovation here is that it adapts to your specific data coverage rather than assuming global coverage.\n",
    "\n",
    "## **_build_neighbor_index()**\n",
    "\n",
    "This function implements a strategy for creating 3×3 patches on the sphere. For each available cell in your dataset (optionally subsampled by stride), it uses HEALPix's `get_all_neighbours()` to find the 8 surrounding cells. However, since the data only covers a specific region, some of these neighbors might not exist in your dataset. The function handles this by replacing any missing neighbors with the center cell ID itself - effectively implementing \"same padding\" at the boundaries. This ensures every patch has exactly 9 elements (center + 8 neighbors), making it compatible with standard CNN operations while preserving the spherical topology.\n",
    "\n",
    "## **_convert_to_data_indices()**\n",
    "\n",
    "This function performs a crucial optimization for computational efficiency. While `_build_neighbor_index()` works with HEALPix cell IDs (which can be large, sparse numbers), your actual data array uses sequential indices from 0 to N-1. This function creates a mapping that converts the HEALPix cell IDs in each patch to the corresponding positions in your data array. This pre-computation means that during the forward pass, you can directly index into your data tensor without expensive lookups, making the convolution much faster.\n",
    "\n",
    "## **forward()**\n",
    "\n",
    "This is where the actual spherical convolution happens. The function takes the input tensor of shape [batch, channels, cells] and extracts all the 3×3 patches simultaneously using advanced indexing. It reshapes these patches into a format suitable for PyTorch's 1D convolution (which treats each 9-element patch as a \"sequence\"), applies the learned convolutional weights, and returns the feature maps. The beauty of this approach is that it maintains the spherical neighborhood relationships while leveraging standard CNN operations, allowing you to use existing deep learning frameworks efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34b4d2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/eopf/lib/python3.11/site-packages/xarray/backends/api.py:651: RuntimeWarning: 'netcdf4' fails while guessing\n",
      "  engine = plugins.guess_engine(filename_or_obj)\n",
      "/home/ubuntu/miniconda3/envs/eopf/lib/python3.11/site-packages/xarray/backends/api.py:651: RuntimeWarning: 'h5netcdf' fails while guessing\n",
      "  engine = plugins.guess_engine(filename_or_obj)\n",
      "/home/ubuntu/miniconda3/envs/eopf/lib/python3.11/site-packages/xarray/backends/api.py:651: RuntimeWarning: 'scipy' fails while guessing\n",
      "  engine = plugins.guess_engine(filename_or_obj)\n"
     ]
    }
   ],
   "source": [
    "ds_healpix = xr.open_dataset(\"/home/ubuntu/project/sentinel-2-dggs-ai-processor/src/notebook/healpix.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc4a35d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Setting up Spherical Convolution ===\n",
      "Available bands: ['b02' 'b03' 'b04' 'b08']\n",
      "Number of available HEALPix cells: 2159668\n",
      "Multi-band data shape: (4, 2159668)\n",
      "Created conv layer with 4 input channels, 64 output channels\n",
      "Number of patches that will be generated: 1079834\n",
      "Input tensor shape: torch.Size([1, 4, 2159668])\n",
      "Output tensor shape: torch.Size([1, 64, 1079834])\n",
      "Output as numpy array: (64, 1079834)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Setting up Spherical Convolution ===\")\n",
    "# 1. Extract spectral data for all bands\n",
    "band_list = ds_healpix.Sentinel2.bands.values\n",
    "print(f\"Available bands: {band_list}\")\n",
    "\n",
    "# 2. Get available cell IDs from your dataset\n",
    "available_cell_ids = ds_healpix.cell_ids.values\n",
    "print(f\"Number of available HEALPix cells: {len(available_cell_ids)}\")\n",
    "\n",
    "# 3. Create input tensor with all spectral bands\n",
    "# Shape: [n_bands, n_cells]\n",
    "spectral_data = []\n",
    "for band in band_list:\n",
    "    band_data = ds_healpix.Sentinel2.sel(bands=band).compute().values\n",
    "    spectral_data.append(band_data)\n",
    "\n",
    "# Stack all bands: [n_bands, n_cells]\n",
    "x_multi_band = np.stack(spectral_data, axis=0)\n",
    "print(f\"Multi-band data shape: {x_multi_band.shape}\")\n",
    "\n",
    "# 4. Create spherical conv layer\n",
    "conv_layer = RegionalSphericalConv(\n",
    "    available_cell_ids=available_cell_ids,\n",
    "    level=19,\n",
    "    in_channels=len(band_list),\n",
    "    out_channels=64,\n",
    "    stride=2\n",
    ")\n",
    "\n",
    "print(f\"Created conv layer with {len(band_list)} input channels, 64 output channels\")\n",
    "print(f\"Number of patches that will be generated: {conv_layer.n_patches}\")\n",
    "\n",
    "# 5. Convert to PyTorch tensor and add batch dimension\n",
    "x_tensor = torch.tensor(x_multi_band, dtype=torch.float32).unsqueeze(0)\n",
    "print(f\"Input tensor shape: {x_tensor.shape}\")  # [1, n_bands, n_cells]\n",
    "\n",
    "# 6. Forward pass\n",
    "with torch.no_grad():\n",
    "    output = conv_layer(x_tensor)\n",
    "    print(f\"Output tensor shape: {output.shape}\")  # [1, 64, n_patches]\n",
    "\n",
    "# 7. Optional: Convert back to numpy for further processing\n",
    "output_np = output.squeeze(0).numpy()  # Remove batch dimension\n",
    "print(f\"Output as numpy array: {output_np.shape}\")  # [64, n_patches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c09486f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "\n",
    "class SphericalConv(nn.Module):\n",
    "    def __init__(self, available_cell_ids, level, in_channels, out_channels, bias=True, nest=True, stride=1):\n",
    "        \"\"\"\n",
    "        Regional Spherical Convolutional layer for HEALPix data covering a specific area.\n",
    "        \"\"\"\n",
    "        super(SphericalConv, self).__init__()\n",
    "\n",
    "        self.level = level\n",
    "        self.NSIDE = 2 ** level\n",
    "        self.nest = nest\n",
    "        self.stride = stride\n",
    "        self.available_cell_ids = np.array(available_cell_ids)\n",
    "        self.available_cell_set = set(available_cell_ids)\n",
    "\n",
    "        # Build neighbor index using your strategy\n",
    "        self.neighbor_indices = self._build_neighbor_index()\n",
    "        self.n_patches = self.neighbor_indices.shape[0]\n",
    "\n",
    "        # Create cell_id to data_index mapping\n",
    "        self.cell_to_data_idx = {cell_id: i for i, cell_id in enumerate(self.available_cell_ids)}\n",
    "\n",
    "        # Convert neighbor indices to data indices for efficient lookup\n",
    "        self.data_neighbor_indices = self._convert_to_data_indices()\n",
    "\n",
    "        # 1D convolution with kernel size 9 (3x3 patch flattened)\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size=9, stride=9, bias=bias)\n",
    "\n",
    "        # Initialize weights\n",
    "        nn.init.kaiming_normal_(self.conv.weight)\n",
    "        if bias:\n",
    "            nn.init.constant_(self.conv.bias, 0.0)\n",
    "\n",
    "    def _build_neighbor_index(self):\n",
    "        \"\"\"Build 9-cell neighborhood index\"\"\"\n",
    "        available_cell_ids = set(self.available_cell_ids)\n",
    "        neighbor_indices = []\n",
    "\n",
    "        # Apply stride to center cell list\n",
    "        center_cells = self.available_cell_ids[::self.stride]\n",
    "\n",
    "        for cell_id in center_cells:\n",
    "            neighbors = hp.get_all_neighbours(self.NSIDE, cell_id, nest=self.nest)\n",
    "\n",
    "            # Validate each neighbor; replace invalid or missing with center\n",
    "            valid_neighbors = [\n",
    "                n if (n != -1 and n in available_cell_ids) else cell_id\n",
    "                for n in neighbors\n",
    "            ]\n",
    "\n",
    "            patch = [cell_id] + valid_neighbors  # Center + 8 neighbors\n",
    "            neighbor_indices.append(patch)\n",
    "\n",
    "        return np.array(neighbor_indices)\n",
    "\n",
    "    def _convert_to_data_indices(self):\n",
    "        \"\"\"Convert HEALPix cell IDs to data array indices\"\"\"\n",
    "        data_indices = np.zeros_like(self.neighbor_indices)\n",
    "\n",
    "        for i, patch in enumerate(self.neighbor_indices):\n",
    "            for j, cell_id in enumerate(patch):\n",
    "                data_indices[i, j] = self.cell_to_data_idx[cell_id]\n",
    "\n",
    "        return torch.tensor(data_indices, dtype=torch.long)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        batch_size, n_channels, n_cells = x.shape\n",
    "\n",
    "        # Ensure we have the right number of cells\n",
    "        assert n_cells == len(self.available_cell_ids), \\\n",
    "            f\"Expected {len(self.available_cell_ids)} cells, got {n_cells}\"\n",
    "\n",
    "        # Extract patches using the neighbor indices\n",
    "        # Shape: [B, C_in, N_patches, 9]\n",
    "        patches = x[:, :, self.data_neighbor_indices]\n",
    "\n",
    "        # Reshape to [B, C_in, N_patches * 9] for Conv1d\n",
    "        patches_flat = patches.view(batch_size, n_channels, -1)\n",
    "\n",
    "        # Apply convolution\n",
    "        output = self.conv(patches_flat)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class SphericalConvBlock(nn.Module):\n",
    "    \"\"\"Basic convolutional block with batch norm and ReLU\"\"\"\n",
    "\n",
    "    def __init__(self, available_cell_ids, level, in_channels, out_channels, stride=1):\n",
    "        super(SphericalConvBlock, self).__init__()\n",
    "\n",
    "        self.conv = SphericalConv(\n",
    "            available_cell_ids=available_cell_ids,\n",
    "            level=level,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            stride=stride\n",
    "        )\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SphericalDoubleConvBlock(nn.Module):\n",
    "    \"\"\"Double convolution block (Conv -> BN -> ReLU -> Conv -> BN -> ReLU)\"\"\"\n",
    "\n",
    "    def __init__(self, available_cell_ids, level, in_channels, out_channels, stride=1):\n",
    "        super(SphericalDoubleConvBlock, self).__init__()\n",
    "\n",
    "        # First conv with specified stride\n",
    "        self.conv1 = SphericalConvBlock(\n",
    "            available_cell_ids=available_cell_ids,\n",
    "            level=level,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            stride=stride\n",
    "        )\n",
    "\n",
    "        # Second conv with stride=1 (operating on the output of first conv)\n",
    "        # We need to determine the output size after first conv\n",
    "        n_patches_after_first = len(available_cell_ids) // stride\n",
    "\n",
    "        self.conv2 = SphericalConvBlock(\n",
    "            available_cell_ids=available_cell_ids,  # This is approximate\n",
    "            level=level,\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            stride=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"Simple model that just applies SphericalDoubleConv\n",
    "    TBD for a UNET later\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, available_cell_ids, level, in_channels, out_channels, stride=1):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.double_conv = SphericalDoubleConvBlock(\n",
    "            available_cell_ids=available_cell_ids,\n",
    "            level=level,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            stride=stride\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "612a3a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Spherical U-Net:\n",
      "  - Input cells: 2159668\n",
      "  - Input channels: 4 (bands: ['b02' 'b03' 'b04' 'b08'])\n",
      "  - Output classes: 4\n",
      "  - HEALPix level: 19\n"
     ]
    }
   ],
   "source": [
    "# Extract available cell IDs from your dataset\n",
    "available_cell_ids = ds_healpix.cell_ids.values\n",
    "level = 19  # Your HEALPix level\n",
    "in_channels = len(band_list)\n",
    "stride = 1\n",
    "print(f\"Creating Spherical U-Net:\")\n",
    "print(f\"  - Input cells: {len(available_cell_ids)}\")\n",
    "print(f\"  - Input channels: {in_channels} (bands: {band_list})\")\n",
    "print(f\"  - Output classes: {in_channels}\")\n",
    "print(f\"  - HEALPix level: {level}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78352e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of available HEALPix cells: 2159668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/eopf/lib/python3.11/site-packages/xarray/backends/api.py:651: RuntimeWarning: 'netcdf4' fails while guessing\n",
      "  engine = plugins.guess_engine(filename_or_obj)\n",
      "/home/ubuntu/miniconda3/envs/eopf/lib/python3.11/site-packages/xarray/backends/api.py:651: RuntimeWarning: 'h5netcdf' fails while guessing\n",
      "  engine = plugins.guess_engine(filename_or_obj)\n",
      "/home/ubuntu/miniconda3/envs/eopf/lib/python3.11/site-packages/xarray/backends/api.py:651: RuntimeWarning: 'scipy' fails while guessing\n",
      "  engine = plugins.guess_engine(filename_or_obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Total parameters: 312\n",
      "Multi-band data shape: (4, 2159668)\n",
      "Input tensor shape: torch.Size([1, 4, 2159668])\n",
      "Output tensor shape: torch.Size([1, 4, 2159668])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Your code with minimal fixes\n",
    "ds_healpix = xr.open_dataset(\"/home/ubuntu/project/sentinel-2-dggs-ai-processor/src/notebook/healpix.zarr\")\n",
    "\n",
    "# 2. Get available cell IDs from your dataset\n",
    "available_cell_ids = ds_healpix.cell_ids.values\n",
    "print(f\"Number of available HEALPix cells: {len(available_cell_ids)}\")\n",
    "\n",
    "model = Model(\n",
    "        available_cell_ids=available_cell_ids,\n",
    "        level=level,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=in_channels,\n",
    "        stride=stride\n",
    "    )\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Calculate total parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"  - Total parameters: {total_params:,}\")\n",
    "\n",
    "# 3. Create input tensor with all spectral bands\n",
    "# Shape: [n_bands, n_cells]\n",
    "spectral_data = []\n",
    "for band in band_list:\n",
    "    band_data = ds_healpix.Sentinel2.sel(bands=band).compute().values\n",
    "    spectral_data.append(band_data)\n",
    "\n",
    "# Stack all bands: [n_bands, n_cells]\n",
    "x_multi_band = np.stack(spectral_data, axis=0)\n",
    "print(f\"Multi-band data shape: {x_multi_band.shape}\")\n",
    "\n",
    "# 5. Convert to PyTorch tensor and add batch dimension\n",
    "x_tensor = torch.tensor(x_multi_band, dtype=torch.float32).unsqueeze(0)\n",
    "print(f\"Input tensor shape: {x_tensor.shape}\")  # [1, n_bands, n_cells]\n",
    "\n",
    "# Move input to GPU\n",
    "x_tensor = x_tensor.to(device)\n",
    "\n",
    "# 6. Forward pass\n",
    "with torch.no_grad():\n",
    "    output = model(x_tensor)  # Fixed: was SphericalUNet(x_tensor)\n",
    "    print(f\"Output tensor shape: {output.shape}\")  # Fixed: was output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50ed07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6b76417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22792b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import segmentation_models_pytorch as smp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "302cb9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43320c83240942febf1a7e2f7dcd26e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e058291c890e4a3bb843a8ba5e7a5c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet18\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=3,                      # model output channels (number of classes in your dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8f1eea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): UnetDecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): UnetDecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): UnetDecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): UnetDecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): UnetDecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b512d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eopf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
