{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb546894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import natsort\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xdggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b79c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"V4\"\n",
    "TRAIN_DIR = f\"/mnt/disk/dataset/sentinel-ai-processor/{version}/train/input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e88bd04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List zarr fil in a given directory\n",
    "zarr_path = natsort.natsorted(glob.glob(os.path.join(TRAIN_DIR, \"*.zarr\"), recursive=False))\n",
    "# Open a zarr product\n",
    "dt = xr.open_datatree(zarr_path[11], engine=\"zarr\", mask_and_scale=False, chunks={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1c3a765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bands(data_tree, res):\n",
    "\n",
    "    res_key = f\"r{res}\"\n",
    "    bands = data_tree.measurements.reflectance[res_key]\n",
    "    return list(bands.keys())\n",
    "\n",
    "def get_chunk(data_tree, res, chunk_y_idx, chunk_x_idx, chunk_size_y, chunk_size_x):\n",
    "    \"\"\"\n",
    "    Extract a specific chunk from a given band at a given spatial resolution in a DataTree.\n",
    "\n",
    "    Parameters:\n",
    "    - data_tree: xarray.DataTree\n",
    "        The root DataTree object loaded from a Zarr store (e.g., xr.open_datatree(...)).\n",
    "    - band: str\n",
    "        The band name to extract (e.g., \"b03\").\n",
    "    - res: str\n",
    "        The spatial resolution as a string (e.g., \"10m\", \"20m\", \"60m\").\n",
    "    - chunk_y_idx: int\n",
    "        Index of the chunk along the vertical (y) axis.\n",
    "    - chunk_x_idx: int\n",
    "        Index of the chunk along the horizontal (x) axis.\n",
    "\n",
    "    Returns:\n",
    "    - xarray.DataArray\n",
    "        A DataArray corresponding to the specified chunk.\n",
    "    \"\"\"\n",
    "    res_key = f\"r{res}\"\n",
    "    y_res = f\"y_{res}\"\n",
    "    x_res = f\"x_{res}\"\n",
    "    data = data_tree.measurements.reflectance[res_key]\n",
    "\n",
    "    y_start = chunk_y_idx * chunk_size_y\n",
    "    x_start = chunk_x_idx * chunk_size_x\n",
    "    return data.isel(\n",
    "        {y_res: slice(y_start, y_start + chunk_size_y),\n",
    "         x_res: slice(x_start, x_start + chunk_size_x)}\n",
    "    )\n",
    "\n",
    "def get_chunk_info(data_tree, band, res):\n",
    "    \"\"\"\n",
    "    Extract chunk size and number of chunks from a dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - data_tree: xarray.DataTree\n",
    "    - band: str, e.g. \"b03\"\n",
    "    - resolution: str, y-dimension name (e.g. \"y_10m\")\n",
    "    - x_res: str, x-dimension name (e.g. \"x_10m\")\n",
    "\n",
    "    Returns:\n",
    "    - chunk_size_y: int\n",
    "    - chunk_size_x: int\n",
    "    - nb_chunks_y: int\n",
    "    - nb_chunks_x: int\n",
    "    \"\"\"\n",
    "    res_key = f\"r{res}\"\n",
    "    y_res = f\"y_{res}\"\n",
    "    x_res = f\"x_{res}\"\n",
    "    data_tree = data_tree.measurements.reflectance[res_key]\n",
    "\n",
    "    chunk_size_y = data_tree[band].chunksizes[y_res][0]\n",
    "    chunk_size_x = data_tree[band].chunksizes[x_res][0]\n",
    "    nb_chunks_y = len(data_tree[band].chunksizes[y_res])\n",
    "    nb_chunks_x = len(data_tree[band].chunksizes[x_res])\n",
    "\n",
    "    print(f\"Chunk size: y={chunk_size_y}, x={chunk_size_x}\")\n",
    "    print(f\"Number of chunks: y={nb_chunks_y}, x={nb_chunks_x}\")\n",
    "\n",
    "    return chunk_size_y, chunk_size_x, nb_chunks_y, nb_chunks_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2914cdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size: y=1830, x=1830\n",
      "Number of chunks: y=6, x=6\n"
     ]
    }
   ],
   "source": [
    "res = \"10m\"\n",
    "band_list = get_bands(data_tree=dt, res=res)\n",
    "chunk_size_y, chunk_size_x, nb_chunks_y, nb_chunks_x = get_chunk_info(data_tree=dt, band=band_list[0], res=res)\n",
    "chunk = get_chunk(data_tree=dt, res=res, chunk_size_y=chunk_size_y,chunk_size_x=chunk_size_x, chunk_y_idx=3, chunk_x_idx=2).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f664522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numcodecs import Zstd\n",
    "\n",
    "class proj_odysea:\n",
    "    \"\"\"\n",
    "    HEALPix projection class for spatial data aggregation compatible with xdggs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        level,\n",
    "        heal_idx,\n",
    "        inv_idx,\n",
    "        nscale=2,\n",
    "        nest=False,\n",
    "        chunk_size=4096,\n",
    "        cell_id_name=\"cell_ids\",\n",
    "    ):\n",
    "        self.level = level\n",
    "        self.nside = 2**(level)\n",
    "        self.nscale = nscale\n",
    "        self.nest = nest\n",
    "        self.chunk_size = chunk_size\n",
    "        self.cell_id_name = cell_id_name\n",
    "\n",
    "        # HEALPix cell setup with ONLY xdggs-compatible attributes\n",
    "        self.cell_ids = heal_idx.flatten()\n",
    "        self.var_cell_ids = xr.DataArray(\n",
    "            self.cell_ids,\n",
    "            dims=\"cells\",\n",
    "            attrs={\n",
    "                \"grid_name\": \"healpix\",\n",
    "                \"indexing_scheme\": \"nested\" if self.nest else \"ring\",\n",
    "                \"resolution\": self.level,\n",
    "                # Remove ALL legacy attributes that cause conflicts\n",
    "            }\n",
    "        )\n",
    "        self.inv_idx = inv_idx.flatten()\n",
    "        self.him = np.bincount(self.inv_idx)\n",
    "\n",
    "    def eval(self, ds):\n",
    "        \"\"\"\n",
    "        Convert dataset to HEALPix projection without time dimension\n",
    "        \"\"\"\n",
    "        var_name = list(ds.data_vars)\n",
    "        print(f\"Processing {len(var_name)} variables: {var_name}\")\n",
    "\n",
    "        # Initialize 2D data array (bands, cells)\n",
    "        all_data = np.zeros([len(var_name), self.cell_ids.shape[0]])\n",
    "\n",
    "        # Process each variable\n",
    "        for i in range(len(var_name)):\n",
    "            ivar = var_name[i]\n",
    "            print(f\"Processing {ivar} ({i+1}/{len(var_name)})\")\n",
    "\n",
    "            # Flatten spatial data\n",
    "            b_data = ds[ivar].values.flatten()\n",
    "\n",
    "            # Find valid data (non-zero and non-NaN)\n",
    "            idx = np.where((b_data != 0) & (~np.isnan(b_data)))\n",
    "\n",
    "            # Aggregate to HEALPix cells\n",
    "            data = np.bincount(\n",
    "                self.inv_idx[idx],\n",
    "                weights=b_data[idx],\n",
    "                minlength=self.cell_ids.shape[0]\n",
    "            )\n",
    "\n",
    "            # Count pixels per cell\n",
    "            hdata = np.bincount(\n",
    "                self.inv_idx[idx],\n",
    "                minlength=self.cell_ids.shape[0]\n",
    "            )\n",
    "\n",
    "            # Calculate mean (handle division by zero)\n",
    "            data = data.astype(float)\n",
    "            data[hdata == 0] = np.nan\n",
    "            valid_mask = hdata > 0\n",
    "            data[valid_mask] = data[valid_mask] / hdata[valid_mask]\n",
    "\n",
    "            # Store in 2D array\n",
    "            all_data[i] = data\n",
    "\n",
    "        # Create DataArray with correct dimensions\n",
    "        data_array = xr.DataArray(\n",
    "            all_data,\n",
    "            dims=(\"bands\", \"cells\"),\n",
    "            coords={\n",
    "                \"bands\": var_name,\n",
    "                self.cell_id_name: self.var_cell_ids\n",
    "            },\n",
    "            name='Sentinel2',\n",
    "            attrs={\n",
    "                \"description\": \"Sentinel-2 reflectance aggregated to HEALPix cells\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Convert to Dataset\n",
    "        ds_total = data_array.to_dataset()\n",
    "\n",
    "        # Set ONLY xdggs-compatible attributes (no extra attributes)\n",
    "        ds_total[self.cell_id_name].attrs = {\n",
    "            \"grid_name\": \"healpix\",\n",
    "            \"indexing_scheme\": \"nested\" if self.nest else \"ring\",\n",
    "            \"resolution\": self.level,\n",
    "        }\n",
    "\n",
    "        # Apply chunking\n",
    "        chunk_size_data = max(1, int((12 * (4**self.level)) / self.chunk_size))\n",
    "        ds_total = ds_total.chunk({\"cells\": chunk_size_data})\n",
    "\n",
    "        print(f\"HEALPix conversion complete - Level {self.level}, {len(self.cell_ids):,} cells\")\n",
    "\n",
    "        return ds_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95dce96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def healpix_projection(dt, res=\"10m\", chunk=True, level=19, chunk_size=4096):\n",
    "    import numpy as np\n",
    "    import healpy as hp\n",
    "    from pyproj import Transformer\n",
    "\n",
    "    # 1. Extract data and grid\n",
    "    if chunk==True:\n",
    "\n",
    "        band_list = get_bands(data_tree=dt, res=res)\n",
    "        chunk_size_y, chunk_size_x, nb_chunks_y, nb_chunks_x = get_chunk_info(data_tree=dt, band=band_list[0], res=res)\n",
    "        ds = get_chunk(data_tree=dt, res=res, chunk_size_y=chunk_size_y,chunk_size_x=chunk_size_x, chunk_y_idx=3, chunk_x_idx=2).load()\n",
    "\n",
    "\n",
    "    else:\n",
    "        ds = dt.measurements.reflectance[f\"r{res}\"]\n",
    "\n",
    "    x = ds[\"x\"].values\n",
    "    y = ds[\"y\"].values\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "    print(f\"Coordinate grid shape: {xx.shape}\")\n",
    "    print(f\"X range: {x.min():.0f} to {x.max():.0f}\")\n",
    "    print(f\"Y range: {y.min():.0f} to {y.max():.0f}\")\n",
    "\n",
    "    # 2. Transform UTM to lat/lon\n",
    "    utm_crs = dt.other_metadata[\"horizontal_CRS_code\"]\n",
    "    transformer = Transformer.from_crs(utm_crs, \"EPSG:4326\", always_xy=True)\n",
    "    lon, lat = transformer.transform(xx, yy)\n",
    "\n",
    "    # 3. Generate HEALPix indices\n",
    "    nside = 2 ** level\n",
    "    idx = hp.ang2pix(nside, lon, lat, lonlat=True, nest=True)\n",
    "    lidx, ilidx = np.unique(idx, return_inverse=True)\n",
    "\n",
    "    print(f\"HEALPix Level {level} → {len(lidx):,} unique cells\")\n",
    "\n",
    "    # 4. Project to HEALPix using your custom class\n",
    "    proj = proj_odysea(level, lidx, ilidx, nest=True, chunk_size=chunk_size)\n",
    "    ds_healpix = proj.eval(ds.to_dataset())\n",
    "\n",
    "    # # 5. Decode to add lat/lon if available via xdggs\n",
    "    # if \"xdggs\" in globals():\n",
    "    ds_healpix = ds_healpix.pipe(xdggs.decode)\n",
    "\n",
    "    return ds_healpix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c08722f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size: y=1830, x=1830\n",
      "Number of chunks: y=6, x=6\n",
      "Coordinate grid shape: (1830, 1830)\n",
      "X range: 736565 to 754855\n",
      "Y range: 5126825 to 5145115\n",
      "HEALPix Level 19 → 2,159,668 unique cells\n",
      "Processing 4 variables: ['b02', 'b03', 'b04', 'b08']\n",
      "Processing b02 (1/4)\n",
      "Processing b03 (2/4)\n",
      "Processing b04 (3/4)\n",
      "Processing b08 (4/4)\n",
      "HEALPix conversion complete - Level 19, 2,159,668 cells\n"
     ]
    }
   ],
   "source": [
    "ds_healpix = healpix_projection(dt=dt, res=\"10m\", chunk=True, level=19, chunk_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0255cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lonboard\n",
    "\n",
    "def create_arrow_table(polygons, arr, coords=None):\n",
    "    from arro3.core import Array, ChunkedArray, Schema, Table\n",
    "\n",
    "    if coords is None:\n",
    "        coords = [\"latitude\", \"longitude\"]\n",
    "\n",
    "    array = Array.from_arrow(polygons)\n",
    "    name = arr.name or \"data\"\n",
    "    arrow_arrays = {\n",
    "        \"geometry\": array,\n",
    "        \"cell_ids\": ChunkedArray([Array.from_numpy(arr.coords[\"cell_ids\"])]),\n",
    "        name: ChunkedArray([Array.from_numpy(arr.data)]),\n",
    "    } | {\n",
    "        coord: ChunkedArray([Array.from_numpy(arr.coords[coord].data)])\n",
    "        for coord in coords\n",
    "        if coord in arr.coords\n",
    "    }\n",
    "\n",
    "    fields = [array.field.with_name(name) for name, array in arrow_arrays.items()]\n",
    "    schema = Schema(fields)\n",
    "\n",
    "    return Table.from_arrays(list(arrow_arrays.values()), schema=schema)\n",
    "\n",
    "\n",
    "def exploire_layer(\n",
    "    arr,\n",
    "    cell_dim=\"cells\",\n",
    "    cmap=\"viridis\",\n",
    "    center=None,\n",
    "    alpha=None,\n",
    "):\n",
    "    from lonboard import SolidPolygonLayer\n",
    "    from lonboard.colormap import apply_continuous_cmap\n",
    "    from matplotlib import colormaps\n",
    "\n",
    "    if len(arr.dims) != 1 or cell_dim not in arr.dims:\n",
    "        raise ValueError(\n",
    "            f\"exploration only works with a single dimension ('{cell_dim}')\"\n",
    "        )\n",
    "\n",
    "    cell_ids = arr.dggs.coord.data\n",
    "    grid_info = arr.dggs.grid_info\n",
    "\n",
    "    polygons = grid_info.cell_boundaries(cell_ids, backend=\"geoarrow\")\n",
    "\n",
    "    # normalized_data = normalize(arr.variable, center=center)\n",
    "\n",
    "    colormap = colormaps[cmap]\n",
    "    colors = apply_continuous_cmap(arr.variable, colormap, alpha=alpha)\n",
    "\n",
    "    table = create_arrow_table(polygons, arr)\n",
    "    layer = SolidPolygonLayer(table=table, filled=True, get_fill_color=colors)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34672f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use of tanh to concentrate the scale variation for the lower values\n",
    "# lonboard.Map(\n",
    "#     [\n",
    "#         exploire_layer(\n",
    "#             ds_healpix.Sentinel2.sel(bands=band_list[-1]).compute(),\n",
    "#             alpha=0.80,\n",
    "#             cmap='viridis'\n",
    "#         )\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "405c19ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([185483525589, 185483525590, 185483525591, ..., 186919324224,\n",
       "       186919324288, 186919324289], shape=(2159668,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_healpix.cell_ids.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a00c6cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import healpy as hp\n",
    "def get_closest_neighbor(cell_id, level):\n",
    "    nside = 2 ** level\n",
    "    neighbors = hp.get_all_neighbours(nside, cell_id, nest=True)\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7aeae73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_id = ds_healpix.cell_ids.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b211aee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1f1f1f;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"►\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"▼\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 288B\n",
       "Dimensions:    (bands: 4, cells: 6)\n",
       "Coordinates:\n",
       "  * bands      (bands) &lt;U3 48B &#x27;b02&#x27; &#x27;b03&#x27; &#x27;b04&#x27; &#x27;b08&#x27;\n",
       "  * cell_ids   (cells) int64 48B dask.array&lt;chunksize=(6,), meta=np.ndarray&gt;\n",
       "Dimensions without coordinates: cells\n",
       "Data variables:\n",
       "    Sentinel2  (bands, cells) float64 192B dask.array&lt;chunksize=(4, 6), meta=np.ndarray&gt;\n",
       "Indexes:\n",
       "    cell_ids  HealpixIndex(level=19, indexing_scheme=nested)</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-2a94703a-ff09-415c-8a9f-d2dd62fda699' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-2a94703a-ff09-415c-8a9f-d2dd62fda699' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>bands</span>: 4</li><li><span class='xr-has-index'>cells</span>: 6</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-9a287fdc-138e-4b3f-9ed0-61259c7e8973' class='xr-section-summary-in' type='checkbox'  checked><label for='section-9a287fdc-138e-4b3f-9ed0-61259c7e8973' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>bands</span></div><div class='xr-var-dims'>(bands)</div><div class='xr-var-dtype'>&lt;U3</div><div class='xr-var-preview xr-preview'>&#x27;b02&#x27; &#x27;b03&#x27; &#x27;b04&#x27; &#x27;b08&#x27;</div><input id='attrs-44c65339-bdc9-4fd0-9be0-ec4dda719857' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-44c65339-bdc9-4fd0-9be0-ec4dda719857' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-db07fb00-18c7-4c33-86d0-e8d6a808e97c' class='xr-var-data-in' type='checkbox'><label for='data-db07fb00-18c7-4c33-86d0-e8d6a808e97c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;b02&#x27;, &#x27;b03&#x27;, &#x27;b04&#x27;, &#x27;b08&#x27;], dtype=&#x27;&lt;U3&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>cell_ids</span></div><div class='xr-var-dims'>(cells)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(6,), meta=np.ndarray&gt;</div><input id='attrs-4dc210b4-b14e-49a2-95fe-b3a89dbc8c4f' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-4dc210b4-b14e-49a2-95fe-b3a89dbc8c4f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d6d029ec-9c17-4213-b82f-c6ce6a360d73' class='xr-var-data-in' type='checkbox'><label for='data-d6d029ec-9c17-4213-b82f-c6ce6a360d73' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>grid_name :</span></dt><dd>healpix</dd><dt><span>indexing_scheme :</span></dt><dd>nested</dd><dt><span>resolution :</span></dt><dd>19</dd></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 48 B </td>\n",
       "                        <td> 48 B </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (6,) </td>\n",
       "                        <td> (6,) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 1 chunks in 2 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> int64 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"91\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"41\" x2=\"120\" y2=\"41\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"41\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"41\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,41.20382942136741 0.0,41.20382942136741\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"61.203829\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >6</text>\n",
       "  <text x=\"140.000000\" y=\"20.601915\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,20.601915)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li></ul></div></li><li class='xr-section-item'><input id='section-8b75c6f2-c49a-4d91-8a05-a13f625478ac' class='xr-section-summary-in' type='checkbox'  checked><label for='section-8b75c6f2-c49a-4d91-8a05-a13f625478ac' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>Sentinel2</span></div><div class='xr-var-dims'>(bands, cells)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(4, 6), meta=np.ndarray&gt;</div><input id='attrs-302efb3b-a002-48f3-bcfc-1982183a0948' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-302efb3b-a002-48f3-bcfc-1982183a0948' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e663608f-fffe-4bc1-a034-148169cfe5e0' class='xr-var-data-in' type='checkbox'><label for='data-e663608f-fffe-4bc1-a034-148169cfe5e0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description :</span></dt><dd>Sentinel-2 reflectance aggregated to HEALPix cells</dd></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 192 B </td>\n",
       "                        <td> 192 B </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (4, 6) </td>\n",
       "                        <td> (4, 6) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 1 chunks in 2 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float64 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"130\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"80\" x2=\"120\" y2=\"80\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"80\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"80\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,80.0 0.0,80.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"100.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >6</text>\n",
       "  <text x=\"140.000000\" y=\"40.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,40.000000)\">4</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li></ul></div></li><li class='xr-section-item'><input id='section-d0722846-8b88-471e-9b97-cd5dea72017a' class='xr-section-summary-in' type='checkbox'  ><label for='section-d0722846-8b88-471e-9b97-cd5dea72017a' class='xr-section-summary' >Indexes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>bands</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-abccda70-8a2b-4f9c-81b8-d262af4fc1bb' class='xr-index-data-in' type='checkbox'/><label for='index-abccda70-8a2b-4f9c-81b8-d262af4fc1bb' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;b02&#x27;, &#x27;b03&#x27;, &#x27;b04&#x27;, &#x27;b08&#x27;], dtype=&#x27;object&#x27;, name=&#x27;bands&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>cell_ids</div></div><div class='xr-index-preview'>HealpixIndex(level=19, indexing_scheme=nested)</div><input type='checkbox' disabled/><label></label><input id='index-62400b23-9237-44ef-8354-127efd2d2a79' class='xr-index-data-in' type='checkbox'/><label for='index-62400b23-9237-44ef-8354-127efd2d2a79' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>&lt;xdggs.healpix.HealpixIndex object at 0x7510a4ba6710&gt;</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-aa96c617-6399-4f48-a8ed-553f0f43b721' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-aa96c617-6399-4f48-a8ed-553f0f43b721' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 288B\n",
       "Dimensions:    (bands: 4, cells: 6)\n",
       "Coordinates:\n",
       "  * bands      (bands) <U3 48B 'b02' 'b03' 'b04' 'b08'\n",
       "  * cell_ids   (cells) int64 48B dask.array<chunksize=(6,), meta=np.ndarray>\n",
       "Dimensions without coordinates: cells\n",
       "Data variables:\n",
       "    Sentinel2  (bands, cells) float64 192B dask.array<chunksize=(4, 6), meta=np.ndarray>\n",
       "Indexes:\n",
       "    cell_ids  HealpixIndex(level=19, indexing_scheme=nested)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level = 19\n",
    "\n",
    "neighbors = get_closest_neighbor(cell_id, level)\n",
    "\n",
    "# Convert ds_healpix.cell_ids to a set for fast lookup\n",
    "available_cells = set(ds_healpix.cell_ids.values)\n",
    "\n",
    "valid_neighbors = [cell_id] + [n for n in neighbors if n in available_cells]\n",
    "selected_ds_healpix = ds_healpix.sel(cell_ids=valid_neighbors)\n",
    "\n",
    "selected_ds_healpix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e66c77a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([185483525588, 185483525590, 185483525591, 185484224642,\n",
       "       185484224640, 185484224554, 185483525503, 185483525502])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93a3ed2",
   "metadata": {},
   "source": [
    "- The healpix product here generated at level 19\n",
    "- The main goal first is to generate a conv layer that goes througt the product cell_ids index.\n",
    "- Compute the function get_closest_neighbor to get the 8 nearest neighbors in a list and add the central cell_id to it. In total the list shall have 9 cell_ids that represent the index of the product.\n",
    "- With the index we then select the data to apply a 2D conv\n",
    "- The goal is to do this with a stride of 1 and also mitigate the border effect as normal pytorch conv 2D is doing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f750cbca",
   "metadata": {},
   "source": [
    "## build neighbour index \n",
    "\n",
    "The build_neighbor_index function constructs a consistent 9-cell neighbourhood for each HEALPix cell in a dataset at a given resolution level. For each input cell_id, it uses the HEALPix library (Healpy) to retrieve the 8 adjacent neighboring cells using nested indexing. These 8 neighbors, together with the central cell, form a 3×3 patch structure—mimicking the receptive field of a 2D convolutional kernel.\n",
    "\n",
    "While the HEALPix sphere is globally continuous, a real-world dataset may only cover a limited subset of it. As a result, some of the 8 neighbors returned by Healpy may not be present in the dataset. To ensure consistent patch size across all cells, the function performs an intersection between the neighbor list and the available cells in the dataset. Any missing or invalid neighbors are replaced with the central cell ID, effectively simulating 'same' padding at the borders.\n",
    "\n",
    "This approach guarantees that each cell is associated with a 9-element patch (center + 8 neighbors), making the data suitable for spatial operations such as spherical convolutions. The output is a 2D NumPy array of shape (N_cells, 9), where each row corresponds to one patch of cell indices ready to be used in downstream convolutional models.\n",
    "\n",
    "\n",
    "### Information about padding system\n",
    "\n",
    "In convolutional operations (like in a CNN), we often apply a filter (or \"kernel\") over a neighborhood of pixels (e.g., a 3×3 grid). But when the filter reaches the edges of the data, it lacks some neighboring values. To avoid losing spatial coverage or changing the output size, padding is applied — typically by adding zeros or repeating values around the edges.\n",
    "\n",
    "In our HEALPix-based spherical data:\n",
    "\n",
    "- Each cell has up to 8 neighboring cells.\n",
    "- cells near the \"edges\" (e.g., at poles or borders in the pixelization) might not have all 8 valid neighbors.\n",
    "- HEALPix marks these missing neighbors with -1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db8a2b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size: y=1830, x=1830\n",
      "Number of chunks: y=6, x=6\n",
      "Coordinate grid shape: (1830, 1830)\n",
      "X range: 736565 to 754855\n",
      "Y range: 5126825 to 5145115\n",
      "HEALPix Level 19 → 2,159,668 unique cells\n",
      "Processing 4 variables: ['b02', 'b03', 'b04', 'b08']\n",
      "Processing b02 (1/4)\n",
      "Processing b03 (2/4)\n",
      "Processing b04 (3/4)\n",
      "Processing b08 (4/4)\n",
      "HEALPix conversion complete - Level 19, 2,159,668 cells\n"
     ]
    }
   ],
   "source": [
    "ds_healpix = healpix_projection(dt=dt, res=\"10m\", chunk=True, level=19, chunk_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b843f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_neighbor_index(cell_ids, level, available_cell_ids, stride=1):\n",
    "    \"\"\"\n",
    "    Construct a 9-cell neighborhood (center + 8 neighbors) for a subset of HEALPix cell IDs\n",
    "    using a configurable stride, including only neighbors that are actually present.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    cell_ids : array-like\n",
    "        Full list of HEALPix cell IDs.\n",
    "\n",
    "    level : int\n",
    "        HEALPix resolution level. Used to compute NSIDE (NSIDE = 2^level).\n",
    "\n",
    "    available_cell_ids : set or list\n",
    "        Set of valid HEALPix cell IDs from the dataset.\n",
    "\n",
    "    stride : int, optional\n",
    "        Step size to sample center cells (default: 1, use all cell_ids).\n",
    "        Higher values skip more cells, reducing the output size.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray\n",
    "        Array of shape (N_patches, 9) where each row is a 3x3 patch centered on a valid cell.\n",
    "    \"\"\"\n",
    "    nside = 2 ** level\n",
    "    available_cell_ids = set(available_cell_ids)\n",
    "    neighbor_indices = []\n",
    "\n",
    "    # --- Apply stride to center cell list ---\n",
    "    center_cells = cell_ids[::stride]\n",
    "\n",
    "    for cell_id in center_cells:\n",
    "        neighbors = hp.get_all_neighbours(nside, cell_id, nest=True)\n",
    "\n",
    "        # Validate each neighbor; replace invalid or missing with center\n",
    "        valid_neighbors = [\n",
    "            n if (n != -1 and n in available_cell_ids) else cell_id\n",
    "            for n in neighbors\n",
    "        ]\n",
    "\n",
    "        patch = [cell_id] + valid_neighbors  # Center + 8 neighbors\n",
    "        neighbor_indices.append(patch)\n",
    "\n",
    "    return np.array(neighbor_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88befac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_ids = ds_healpix.cell_ids.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d794c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_ids = ds_healpix.cell_ids.values\n",
    "available_cells = set(cell_ids)\n",
    "neighbor_index = build_neighbor_index(cell_ids, level=19, available_cell_ids=available_cells, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3275527a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2159668, 9)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbor_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04799ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3097    , 0.3097    , 0.367     , 0.3532    , 0.34216667,\n",
       "       0.3431    , 0.22      , 0.3097    , 0.3097    ])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert ds_healpix.cell_ids to a set for fast lookup\n",
    "available_cells = set(ds_healpix.cell_ids.values)\n",
    "valid_neighbors = [n for n in neighbor_index[0] if n in available_cells]\n",
    "selected_ds_healpix = ds_healpix.sel(cell_ids=valid_neighbors)\n",
    "selected_ds_healpix.Sentinel2.sel(bands=band_list[-1]).compute().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e3da5ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3097    , 0.3097    , 0.367     , 0.3532    , 0.34216667,\n",
       "       0.3431    , 0.22      , 0.3097    , 0.3097    ])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = selected_ds_healpix.Sentinel2.sel(bands=band_list[-1]).compute().values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfd0c1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([185483525589, 185483525590, 185483525591, 185484224642,\n",
       "       185484224640, 185484224554])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_ds_healpix.Sentinel2.sel(bands=band_list[-1]).cell_ids.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9648ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from notebook.SphericConv import RegionalSphericalConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9d4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_with_your_data():\n",
    "    \"\"\"\n",
    "    Complete example showing how to use the spherical conv with your ds_healpix data\n",
    "    \"\"\"\n",
    "    # Assuming you have your ds_healpix from the healpix_projection function\n",
    "    # and your band_list from get_bands function\n",
    "\n",
    "    print(\"=== Setting up Spherical Convolution ===\")\n",
    "\n",
    "    # 1. Extract spectral data for all bands\n",
    "    band_list = get_bands(data_tree=dt, res=\"10m\")  # Your band list\n",
    "    print(f\"Available bands: {band_list}\")\n",
    "\n",
    "    # 2. Get available cell IDs from your dataset\n",
    "    available_cell_ids = ds_healpix.cell_ids.values\n",
    "    print(f\"Number of available HEALPix cells: {len(available_cell_ids)}\")\n",
    "\n",
    "    # 3. Create input tensor with all spectral bands\n",
    "    # Shape: [n_bands, n_cells]\n",
    "    spectral_data = []\n",
    "    for band in band_list:\n",
    "        band_data = ds_healpix.Sentinel2.sel(bands=band).compute().values\n",
    "        spectral_data.append(band_data)\n",
    "\n",
    "    # Stack all bands: [n_bands, n_cells]\n",
    "    x_multi_band = np.stack(spectral_data, axis=0)\n",
    "    print(f\"Multi-band data shape: {x_multi_band.shape}\")\n",
    "\n",
    "    # 4. Create spherical conv layer\n",
    "    conv_layer = RegionalSphericalConv(\n",
    "        available_cell_ids=available_cell_ids,\n",
    "        level=19,\n",
    "        in_channels=len(band_list),\n",
    "        out_channels=64,\n",
    "        stride=1\n",
    "    )\n",
    "\n",
    "    print(f\"Created conv layer with {len(band_list)} input channels, 64 output channels\")\n",
    "    print(f\"Number of patches that will be generated: {conv_layer.n_patches}\")\n",
    "\n",
    "    # 5. Convert to PyTorch tensor and add batch dimension\n",
    "    x_tensor = torch.tensor(x_multi_band, dtype=torch.float32).unsqueeze(0)\n",
    "    print(f\"Input tensor shape: {x_tensor.shape}\")  # [1, n_bands, n_cells]\n",
    "\n",
    "    # 6. Forward pass\n",
    "    with torch.no_grad():  # For demonstration, no gradients needed\n",
    "        output = conv_layer(x_tensor)\n",
    "        print(f\"Output tensor shape: {output.shape}\")  # [1, 64, n_patches]\n",
    "\n",
    "    # 7. Optional: Convert back to numpy for further processing\n",
    "    output_np = output.squeeze(0).numpy()  # Remove batch dimension\n",
    "    print(f\"Output as numpy array: {output_np.shape}\")  # [64, n_patches]\n",
    "\n",
    "    return conv_layer, x_tensor, output\n",
    "\n",
    "\n",
    "# Example with different stride values\n",
    "def example_with_stride():\n",
    "    \"\"\"\n",
    "    Example showing how stride affects the number of output patches\n",
    "    \"\"\"\n",
    "    available_cell_ids = ds_healpix.cell_ids.values\n",
    "    band_list = get_bands(data_tree=dt, res=\"10m\")\n",
    "\n",
    "    print(\"\\n=== Stride Comparison ===\")\n",
    "\n",
    "    for stride in [1, 2, 4, 8]:\n",
    "        conv_layer = RegionalSphericalConv(\n",
    "            available_cell_ids=available_cell_ids,\n",
    "            level=19,\n",
    "            in_channels=len(band_list),\n",
    "            out_channels=32,\n",
    "            stride=stride\n",
    "        )\n",
    "\n",
    "        reduction_factor = len(available_cell_ids) / conv_layer.n_patches\n",
    "        print(f\"Stride {stride}: {conv_layer.n_patches} patches \"\n",
    "              f\"({reduction_factor:.1f}x reduction from {len(available_cell_ids)} cells)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ef97582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Setting up Spherical Convolution ===\n",
      "Available bands: ['b02', 'b03', 'b04', 'b08']\n",
      "Number of available HEALPix cells: 2159668\n",
      "Multi-band data shape: (4, 2159668)\n",
      "Created conv layer with 4 input channels, 64 output channels\n",
      "Number of patches that will be generated: 2159668\n",
      "Input tensor shape: torch.Size([1, 4, 2159668])\n",
      "Output tensor shape: torch.Size([1, 64, 2159668])\n",
      "Output as numpy array: (64, 2159668)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "conv_layer, input_tensor, output = example_with_your_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc639dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Stride Comparison ===\n",
      "Stride 1: 2159668 patches (1.0x reduction from 2159668 cells)\n",
      "Stride 2: 1079834 patches (2.0x reduction from 2159668 cells)\n",
      "Stride 4: 539917 patches (4.0x reduction from 2159668 cells)\n",
      "Stride 8: 269959 patches (8.0x reduction from 2159668 cells)\n"
     ]
    }
   ],
   "source": [
    "example_with_stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a03a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_cell_ids = ds_healpix.cell_ids.values\n",
    "\n",
    "conv_layer = RegionalSphericalConv(\n",
    "    available_cell_ids=available_cell_ids,\n",
    "    level=level,\n",
    "    in_channels=4,\n",
    "    out_channels=64,\n",
    "    stride=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad73875",
   "metadata": {},
   "source": [
    "## **RegionalSphericalConv.__init__()** \n",
    "This is the constructor that sets up the spherical convolution layer for your regional HEALPix data. Unlike the original implementation that assumes a full sphere, this version works with only the HEALPix cells present in your dataset. It takes your `available_cell_ids` (the cells that actually contain data in your geographic region) and the HEALPix resolution level. The constructor builds the neighbor relationships, creates efficient lookup tables, and initializes the underlying 1D convolution layer that will process the 3×3 patches. The key innovation here is that it adapts to your specific data coverage rather than assuming global coverage.\n",
    "\n",
    "## **_build_neighbor_index()** \n",
    "This function implements your exact strategy for creating 3×3 patches on the sphere. For each available cell in your dataset (optionally subsampled by stride), it uses HEALPix's `get_all_neighbours()` to find the 8 surrounding cells. However, since your data only covers a specific region, some of these neighbors might not exist in your dataset. The function handles this by replacing any missing neighbors with the center cell ID itself - effectively implementing \"same padding\" at the boundaries. This ensures every patch has exactly 9 elements (center + 8 neighbors), making it compatible with standard CNN operations while preserving the spherical topology.\n",
    "\n",
    "## **_convert_to_data_indices()** \n",
    "This function performs a crucial optimization for computational efficiency. While `_build_neighbor_index()` works with HEALPix cell IDs (which can be large, sparse numbers), your actual data array uses sequential indices from 0 to N-1. This function creates a mapping that converts the HEALPix cell IDs in each patch to the corresponding positions in your data array. This pre-computation means that during the forward pass, you can directly index into your data tensor without expensive lookups, making the convolution much faster.\n",
    "\n",
    "## **forward()** \n",
    "This is where the actual spherical convolution happens. The function takes your input tensor of shape [batch, channels, cells] and extracts all the 3×3 patches simultaneously using advanced indexing. It reshapes these patches into a format suitable for PyTorch's 1D convolution (which treats each 9-element patch as a \"sequence\"), applies the learned convolutional weights, and returns the feature maps. The beauty of this approach is that it maintains the spherical neighborhood relationships while leveraging standard CNN operations, allowing you to use existing deep learning frameworks efficiently.\n",
    "\n",
    "## **example_with_your_data()** \n",
    "This comprehensive example demonstrates the complete workflow with your actual HEALPix data. It starts by extracting all spectral bands from your `ds_healpix` dataset, stacks them into a multi-channel tensor (just like RGB channels in regular images), creates the spherical convolution layer, and performs a forward pass. The example shows how your satellite data with multiple spectral bands gets transformed into feature maps that respect the spherical geometry. It also includes practical details like tensor shapes and data type conversions needed for PyTorch.\n",
    "\n",
    "## **example_with_stride()** \n",
    "This function illustrates how the stride parameter affects computational efficiency and spatial resolution. By using different stride values (1, 2, 4, 8), you can control how many patches are generated - stride=1 creates a patch for every available cell, while stride=4 creates patches for every 4th cell, reducing computation by 4×. This is particularly useful for multi-scale processing or when you need to balance computational resources with spatial detail. The function shows the trade-off between spatial resolution and computational efficiency.\n",
    "\n",
    "The key advantage of this approach is that it seamlessly integrates your regional HEALPix strategy with standard deep learning, allowing you to build sophisticated spherical CNNs that work efficiently on your satellite data while respecting the underlying spherical geometry of Earth's surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "115989a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Spherical Convolution Test Suite\n",
      "\n",
      "=== TEST 1: Neighbor Index Logic ===\n",
      "Test region: center=100, neighbors=[ 97  99 102 103 101  79  78  75]\n",
      "Available cells: [100, np.int64(97), np.int64(99), np.int64(102), np.int64(103), np.int64(101), np.int64(79), np.int64(78), np.int64(75)]\n",
      "Generated 9 patches\n",
      "✅ Neighbor index logic test passed!\n",
      "\n",
      "=== TEST 2: Boundary Padding ===\n",
      "Patch 0: center=1000, padding=7/8 neighbors\n",
      "Patch 1: center=1001, padding=7/8 neighbors\n",
      "Patch 2: center=1050, padding=8/8 neighbors\n",
      "✅ Boundary padding test passed!\n",
      "\n",
      "=== TEST 3: Stride Functionality ===\n",
      "Stride 1: 100 patches (expected ~100)\n",
      "Stride 2: 50 patches (expected ~50)\n",
      "Stride 4: 25 patches (expected ~25)\n",
      "Stride 5: 20 patches (expected ~20)\n",
      "✅ Stride functionality test passed!\n",
      "\n",
      "=== TEST 4: Forward Pass Shapes ===\n",
      "Input shape: torch.Size([2, 5, 100])\n",
      "Expected output shape: (2, 16, 100)\n",
      "Actual output shape: torch.Size([2, 16, 100])\n",
      "✅ Forward pass shapes test passed!\n",
      "\n",
      "=== TEST 5: Patch Extraction Correctness ===\n",
      "Input data: tensor([0., 1., 2., 3., 4.])\n",
      "Cell to data mapping: {np.int64(100): 0, np.int64(101): 1, np.int64(102): 2, np.int64(103): 3, np.int64(104): 4}\n",
      "Extracted patches shape: torch.Size([1, 1, 5, 9])\n",
      "First patch values: [0. 0. 0. 2. 3. 1. 0. 0. 0.]\n",
      "First patch cell IDs: [100 100 100 102 103 101 100 100 100]\n",
      "Expected data indices: [0, 0, 0, 2, 3, 1, 0, 0, 0]\n",
      "✅ Patch extraction correctness test passed!\n",
      "\n",
      "=== TEST 6: Gradient Flow ===\n",
      "Input gradient shape: torch.Size([1, 3, 50])\n",
      "Conv weight gradient shape: torch.Size([8, 3, 9])\n",
      "Input gradient norm: 28.799477\n",
      "Weight gradient norm: 218.328033\n",
      "✅ Gradient flow test passed!\n",
      "\n",
      "=== TEST 7: Memory Efficiency ===\n",
      "Input tensor size: 0.31 MB\n",
      "Output tensor size: 0.49 MB\n",
      "Number of patches: 1000\n",
      "✅ Memory efficiency test passed!\n",
      "\n",
      "==================================================\n",
      "TEST SUMMARY\n",
      "==================================================\n",
      "neighbor_index: ✅ PASSED\n",
      "boundary_padding: ✅ PASSED\n",
      "stride: ✅ PASSED\n",
      "forward_shapes: ✅ PASSED\n",
      "patch_extraction: ✅ PASSED\n",
      "gradient_flow: ✅ PASSED\n",
      "memory_efficiency: ✅ PASSED\n",
      "\n",
      "Overall: 7/7 tests passed\n",
      "🎉 ALL TESTS PASSED! The spherical convolution implementation is working correctly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W718 08:11:01.210286836 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W718 08:11:01.224200675 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# First, let's include the RegionalSphericalConv class from the previous artifact\n",
    "class RegionalSphericalConv(nn.Module):\n",
    "    def __init__(self, available_cell_ids, level, in_channels, out_channels, bias=True, nest=True, stride=1):\n",
    "        \"\"\"\n",
    "        Regional Spherical Convolutional layer for HEALPix data covering a specific area.\n",
    "        \"\"\"\n",
    "        super(RegionalSphericalConv, self).__init__()\n",
    "\n",
    "        self.level = level\n",
    "        self.NSIDE = 2 ** level\n",
    "        self.nest = nest\n",
    "        self.stride = stride\n",
    "        self.available_cell_ids = np.array(available_cell_ids)\n",
    "        self.available_cell_set = set(available_cell_ids)\n",
    "\n",
    "        # Build neighbor index using your strategy\n",
    "        self.neighbor_indices = self._build_neighbor_index()\n",
    "        self.n_patches = self.neighbor_indices.shape[0]\n",
    "\n",
    "        # Create cell_id to data_index mapping\n",
    "        self.cell_to_data_idx = {cell_id: i for i, cell_id in enumerate(self.available_cell_ids)}\n",
    "\n",
    "        # Convert neighbor indices to data indices for efficient lookup\n",
    "        self.data_neighbor_indices = self._convert_to_data_indices()\n",
    "\n",
    "        # 1D convolution with kernel size 9 (3x3 patch flattened)\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size=9, stride=9, bias=bias)\n",
    "\n",
    "        # Initialize weights\n",
    "        nn.init.kaiming_normal_(self.conv.weight)\n",
    "        if bias:\n",
    "            nn.init.constant_(self.conv.bias, 0.0)\n",
    "\n",
    "    def _build_neighbor_index(self):\n",
    "        \"\"\"Build 9-cell neighborhood index using your strategy\"\"\"\n",
    "        available_cell_ids = set(self.available_cell_ids)\n",
    "        neighbor_indices = []\n",
    "\n",
    "        # Apply stride to center cell list\n",
    "        center_cells = self.available_cell_ids[::self.stride]\n",
    "\n",
    "        for cell_id in center_cells:\n",
    "            neighbors = hp.get_all_neighbours(self.NSIDE, cell_id, nest=self.nest)\n",
    "\n",
    "            # Validate each neighbor; replace invalid or missing with center\n",
    "            valid_neighbors = [\n",
    "                n if (n != -1 and n in available_cell_ids) else cell_id\n",
    "                for n in neighbors\n",
    "            ]\n",
    "\n",
    "            patch = [cell_id] + valid_neighbors  # Center + 8 neighbors\n",
    "            neighbor_indices.append(patch)\n",
    "\n",
    "        return np.array(neighbor_indices)\n",
    "\n",
    "    def _convert_to_data_indices(self):\n",
    "        \"\"\"Convert HEALPix cell IDs to data array indices\"\"\"\n",
    "        data_indices = np.zeros_like(self.neighbor_indices)\n",
    "\n",
    "        for i, patch in enumerate(self.neighbor_indices):\n",
    "            for j, cell_id in enumerate(patch):\n",
    "                data_indices[i, j] = self.cell_to_data_idx[cell_id]\n",
    "\n",
    "        return torch.tensor(data_indices, dtype=torch.long)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        batch_size, n_channels, n_cells = x.shape\n",
    "\n",
    "        # Ensure we have the right number of cells\n",
    "        assert n_cells == len(self.available_cell_ids), \\\n",
    "            f\"Expected {len(self.available_cell_ids)} cells, got {n_cells}\"\n",
    "\n",
    "        # Extract patches using the neighbor indices\n",
    "        # Shape: [B, C_in, N_patches, 9]\n",
    "        patches = x[:, :, self.data_neighbor_indices]\n",
    "\n",
    "        # Reshape to [B, C_in, N_patches * 9] for Conv1d\n",
    "        patches_flat = patches.view(batch_size, n_channels, -1)\n",
    "\n",
    "        # Apply convolution\n",
    "        output = self.conv(patches_flat)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Test Suite\n",
    "class SphericalConvTestSuite:\n",
    "    def __init__(self):\n",
    "        self.test_results = {}\n",
    "        self.verbose = True\n",
    "\n",
    "    def log(self, message):\n",
    "        if self.verbose:\n",
    "            print(message)\n",
    "\n",
    "    def test_neighbor_index_logic(self):\n",
    "        \"\"\"Test 1: Verify neighbor index construction logic\"\"\"\n",
    "        self.log(\"\\n=== TEST 1: Neighbor Index Logic ===\")\n",
    "\n",
    "        # Create a small test case with known HEALPix cells\n",
    "        level = 3  # Small for testing\n",
    "        nside = 2 ** level\n",
    "\n",
    "        # Create a small region of cells\n",
    "        center_cell = 100\n",
    "        all_neighbors = hp.get_all_neighbours(nside, center_cell, nest=True)\n",
    "        available_cells = [center_cell] + [n for n in all_neighbors if n != -1]\n",
    "\n",
    "        self.log(f\"Test region: center={center_cell}, neighbors={all_neighbors}\")\n",
    "        self.log(f\"Available cells: {available_cells}\")\n",
    "\n",
    "        # Create conv layer\n",
    "        conv_layer = RegionalSphericalConv(\n",
    "            available_cell_ids=available_cells,\n",
    "            level=level,\n",
    "            in_channels=3,\n",
    "            out_channels=16,\n",
    "            stride=1\n",
    "        )\n",
    "\n",
    "        # Check neighbor indices\n",
    "        neighbor_indices = conv_layer.neighbor_indices\n",
    "        self.log(f\"Generated {len(neighbor_indices)} patches\")\n",
    "\n",
    "        # Verify each patch has 9 elements\n",
    "        for i, patch in enumerate(neighbor_indices):\n",
    "            assert len(patch) == 9, f\"Patch {i} has {len(patch)} elements, expected 9\"\n",
    "            # Center should be first element\n",
    "            center = patch[0]\n",
    "            assert center in available_cells, f\"Center {center} not in available cells\"\n",
    "\n",
    "        self.log(\"✅ Neighbor index logic test passed!\")\n",
    "        self.test_results['neighbor_index'] = True\n",
    "\n",
    "    def test_boundary_padding(self):\n",
    "        \"\"\"Test 2: Verify boundary padding with missing neighbors\"\"\"\n",
    "        self.log(\"\\n=== TEST 2: Boundary Padding ===\")\n",
    "\n",
    "        level = 4\n",
    "        nside = 2 ** level\n",
    "\n",
    "        # Create a sparse region where many neighbors will be missing\n",
    "        sparse_cells = [1000, 1001, 1050]  # Scattered cells\n",
    "\n",
    "        conv_layer = RegionalSphericalConv(\n",
    "            available_cell_ids=sparse_cells,\n",
    "            level=level,\n",
    "            in_channels=1,\n",
    "            out_channels=8,\n",
    "            stride=1\n",
    "        )\n",
    "\n",
    "        # Check that missing neighbors are replaced with center\n",
    "        neighbor_indices = conv_layer.neighbor_indices\n",
    "\n",
    "        for i, patch in enumerate(neighbor_indices):\n",
    "            center = patch[0]\n",
    "            neighbors = patch[1:]\n",
    "\n",
    "            # Count how many neighbors are the center (indicating padding)\n",
    "            padding_count = sum(1 for n in neighbors if n == center)\n",
    "\n",
    "            # For sparse data, we expect some padding\n",
    "            self.log(f\"Patch {i}: center={center}, padding={padding_count}/8 neighbors\")\n",
    "\n",
    "            # Verify all elements are valid\n",
    "            for cell_id in patch:\n",
    "                assert cell_id in sparse_cells, f\"Invalid cell {cell_id} in patch\"\n",
    "\n",
    "        self.log(\"✅ Boundary padding test passed!\")\n",
    "        self.test_results['boundary_padding'] = True\n",
    "\n",
    "    def test_stride_functionality(self):\n",
    "        \"\"\"Test 3: Verify stride reduces number of patches correctly\"\"\"\n",
    "        self.log(\"\\n=== TEST 3: Stride Functionality ===\")\n",
    "\n",
    "        level = 3\n",
    "        # Create a larger region\n",
    "        available_cells = list(range(100, 200))  # 100 cells\n",
    "\n",
    "        stride_results = {}\n",
    "\n",
    "        for stride in [1, 2, 4, 5]:\n",
    "            conv_layer = RegionalSphericalConv(\n",
    "                available_cell_ids=available_cells,\n",
    "                level=level,\n",
    "                in_channels=2,\n",
    "                out_channels=10,\n",
    "                stride=stride\n",
    "            )\n",
    "\n",
    "            expected_patches = len(available_cells) // stride\n",
    "            actual_patches = conv_layer.n_patches\n",
    "\n",
    "            stride_results[stride] = {\n",
    "                'expected': expected_patches,\n",
    "                'actual': actual_patches,\n",
    "                'cells': len(available_cells)\n",
    "            }\n",
    "\n",
    "            self.log(f\"Stride {stride}: {actual_patches} patches (expected ~{expected_patches})\")\n",
    "\n",
    "            # Allow for small differences due to integer division\n",
    "            assert abs(actual_patches - expected_patches) <= 1, \\\n",
    "                f\"Stride {stride}: got {actual_patches}, expected ~{expected_patches}\"\n",
    "\n",
    "        self.log(\"✅ Stride functionality test passed!\")\n",
    "        self.test_results['stride'] = True\n",
    "\n",
    "    def test_forward_pass_shapes(self):\n",
    "        \"\"\"Test 4: Verify forward pass produces correct output shapes\"\"\"\n",
    "        self.log(\"\\n=== TEST 4: Forward Pass Shapes ===\")\n",
    "\n",
    "        level = 4\n",
    "        available_cells = list(range(500, 600))  # 100 cells\n",
    "        batch_size = 2\n",
    "        in_channels = 5\n",
    "        out_channels = 16\n",
    "\n",
    "        conv_layer = RegionalSphericalConv(\n",
    "            available_cell_ids=available_cells,\n",
    "            level=level,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            stride=1\n",
    "        )\n",
    "\n",
    "        # Create input tensor\n",
    "        n_cells = len(available_cells)\n",
    "        input_tensor = torch.randn(batch_size, in_channels, n_cells)\n",
    "\n",
    "        self.log(f\"Input shape: {input_tensor.shape}\")\n",
    "\n",
    "        # Forward pass\n",
    "        output = conv_layer(input_tensor)\n",
    "\n",
    "        expected_output_shape = (batch_size, out_channels, conv_layer.n_patches)\n",
    "        actual_output_shape = output.shape\n",
    "\n",
    "        self.log(f\"Expected output shape: {expected_output_shape}\")\n",
    "        self.log(f\"Actual output shape: {actual_output_shape}\")\n",
    "\n",
    "        assert actual_output_shape == expected_output_shape, \\\n",
    "            f\"Shape mismatch: got {actual_output_shape}, expected {expected_output_shape}\"\n",
    "\n",
    "        self.log(\"✅ Forward pass shapes test passed!\")\n",
    "        self.test_results['forward_shapes'] = True\n",
    "\n",
    "    def test_patch_extraction_correctness(self):\n",
    "        \"\"\"Test 5: Verify patch extraction extracts correct values\"\"\"\n",
    "        self.log(\"\\n=== TEST 5: Patch Extraction Correctness ===\")\n",
    "\n",
    "        level = 3\n",
    "        available_cells = [100, 101, 102, 103, 104]\n",
    "\n",
    "        conv_layer = RegionalSphericalConv(\n",
    "            available_cell_ids=available_cells,\n",
    "            level=level,\n",
    "            in_channels=1,\n",
    "            out_channels=4,\n",
    "            stride=1\n",
    "        )\n",
    "\n",
    "        # Create input with known values\n",
    "        input_data = torch.arange(len(available_cells), dtype=torch.float32)\n",
    "        input_tensor = input_data.unsqueeze(0).unsqueeze(0)  # [1, 1, 5]\n",
    "\n",
    "        self.log(f\"Input data: {input_data}\")\n",
    "        self.log(f\"Cell to data mapping: {conv_layer.cell_to_data_idx}\")\n",
    "\n",
    "        # Extract patches manually to verify\n",
    "        patches = input_tensor[:, :, conv_layer.data_neighbor_indices]\n",
    "\n",
    "        self.log(f\"Extracted patches shape: {patches.shape}\")\n",
    "\n",
    "        # Check first patch\n",
    "        first_patch = patches[0, 0, 0, :].numpy()\n",
    "        self.log(f\"First patch values: {first_patch}\")\n",
    "\n",
    "        # Verify patch corresponds to correct neighbor indices\n",
    "        first_patch_cell_ids = conv_layer.neighbor_indices[0]\n",
    "        expected_values = [conv_layer.cell_to_data_idx[cell_id] for cell_id in first_patch_cell_ids]\n",
    "\n",
    "        self.log(f\"First patch cell IDs: {first_patch_cell_ids}\")\n",
    "        self.log(f\"Expected data indices: {expected_values}\")\n",
    "\n",
    "        # The patch should contain the data values at those indices\n",
    "        for i, expected_idx in enumerate(expected_values):\n",
    "            assert first_patch[i] == expected_idx, \\\n",
    "                f\"Patch position {i}: got {first_patch[i]}, expected {expected_idx}\"\n",
    "\n",
    "        self.log(\"✅ Patch extraction correctness test passed!\")\n",
    "        self.test_results['patch_extraction'] = True\n",
    "\n",
    "    def test_gradient_flow(self):\n",
    "        \"\"\"Test 6: Verify gradients flow correctly through the layer\"\"\"\n",
    "        self.log(\"\\n=== TEST 6: Gradient Flow ===\")\n",
    "\n",
    "        level = 4\n",
    "        available_cells = list(range(200, 250))\n",
    "\n",
    "        conv_layer = RegionalSphericalConv(\n",
    "            available_cell_ids=available_cells,\n",
    "            level=level,\n",
    "            in_channels=3,\n",
    "            out_channels=8,\n",
    "            stride=1\n",
    "        )\n",
    "\n",
    "        # Create input that requires gradients\n",
    "        input_tensor = torch.randn(1, 3, len(available_cells), requires_grad=True)\n",
    "\n",
    "        # Forward pass\n",
    "        output = conv_layer(input_tensor)\n",
    "\n",
    "        # Backward pass\n",
    "        loss = output.sum()\n",
    "        loss.backward()\n",
    "\n",
    "        # Check that gradients exist\n",
    "        assert input_tensor.grad is not None, \"No gradients computed for input\"\n",
    "        assert conv_layer.conv.weight.grad is not None, \"No gradients computed for conv weights\"\n",
    "\n",
    "        self.log(f\"Input gradient shape: {input_tensor.grad.shape}\")\n",
    "        self.log(f\"Conv weight gradient shape: {conv_layer.conv.weight.grad.shape}\")\n",
    "\n",
    "        # Check gradient magnitudes are reasonable\n",
    "        input_grad_norm = input_tensor.grad.norm().item()\n",
    "        weight_grad_norm = conv_layer.conv.weight.grad.norm().item()\n",
    "\n",
    "        assert input_grad_norm > 0, \"Input gradients are zero\"\n",
    "        assert weight_grad_norm > 0, \"Weight gradients are zero\"\n",
    "\n",
    "        self.log(f\"Input gradient norm: {input_grad_norm:.6f}\")\n",
    "        self.log(f\"Weight gradient norm: {weight_grad_norm:.6f}\")\n",
    "\n",
    "        self.log(\"✅ Gradient flow test passed!\")\n",
    "        self.test_results['gradient_flow'] = True\n",
    "\n",
    "    def test_memory_efficiency(self):\n",
    "        \"\"\"Test 7: Check memory usage for larger datasets\"\"\"\n",
    "        self.log(\"\\n=== TEST 7: Memory Efficiency ===\")\n",
    "\n",
    "        level = 6  # Larger level\n",
    "        available_cells = list(range(1000, 3000))  # 2000 cells\n",
    "\n",
    "        conv_layer = RegionalSphericalConv(\n",
    "            available_cell_ids=available_cells,\n",
    "            level=level,\n",
    "            in_channels=10,\n",
    "            out_channels=32,\n",
    "            stride=2  # Use stride to reduce memory\n",
    "        )\n",
    "\n",
    "        # Create reasonably large input\n",
    "        input_tensor = torch.randn(4, 10, len(available_cells))  # 4 batches\n",
    "\n",
    "        self.log(f\"Input tensor size: {input_tensor.numel() * 4 / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "        # Forward pass\n",
    "        output = conv_layer(input_tensor)\n",
    "\n",
    "        self.log(f\"Output tensor size: {output.numel() * 4 / 1024 / 1024:.2f} MB\")\n",
    "        self.log(f\"Number of patches: {conv_layer.n_patches}\")\n",
    "\n",
    "        # Basic sanity check\n",
    "        assert output.shape[0] == 4, \"Batch dimension incorrect\"\n",
    "        assert output.shape[1] == 32, \"Channel dimension incorrect\"\n",
    "\n",
    "        self.log(\"✅ Memory efficiency test passed!\")\n",
    "        self.test_results['memory_efficiency'] = True\n",
    "\n",
    "    def run_all_tests(self):\n",
    "        \"\"\"Run all tests and provide summary\"\"\"\n",
    "        self.log(\"🚀 Starting Spherical Convolution Test Suite\")\n",
    "\n",
    "        test_methods = [\n",
    "            self.test_neighbor_index_logic,\n",
    "            self.test_boundary_padding,\n",
    "            self.test_stride_functionality,\n",
    "            self.test_forward_pass_shapes,\n",
    "            self.test_patch_extraction_correctness,\n",
    "            self.test_gradient_flow,\n",
    "            self.test_memory_efficiency\n",
    "        ]\n",
    "\n",
    "        for test_method in test_methods:\n",
    "            try:\n",
    "                test_method()\n",
    "            except Exception as e:\n",
    "                test_name = test_method.__name__\n",
    "                self.log(f\"❌ {test_name} FAILED: {str(e)}\")\n",
    "                self.test_results[test_name] = False\n",
    "\n",
    "        self.print_summary()\n",
    "\n",
    "    def print_summary(self):\n",
    "        \"\"\"Print test summary\"\"\"\n",
    "        self.log(\"\\n\" + \"=\"*50)\n",
    "        self.log(\"TEST SUMMARY\")\n",
    "        self.log(\"=\"*50)\n",
    "\n",
    "        passed = sum(1 for result in self.test_results.values() if result)\n",
    "        total = len(self.test_results)\n",
    "\n",
    "        for test_name, result in self.test_results.items():\n",
    "            status = \"✅ PASSED\" if result else \"❌ FAILED\"\n",
    "            self.log(f\"{test_name}: {status}\")\n",
    "\n",
    "        self.log(f\"\\nOverall: {passed}/{total} tests passed\")\n",
    "\n",
    "        if passed == total:\n",
    "            self.log(\"🎉 ALL TESTS PASSED! The spherical convolution implementation is working correctly.\")\n",
    "        else:\n",
    "            self.log(\"⚠️  Some tests failed. Please review the implementation.\")\n",
    "\n",
    "\n",
    "test_suite = SphericalConvTestSuite()\n",
    "test_suite.run_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb6cd10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running comprehensive test suite...\n",
      "🚀 Starting Spherical Convolution Test Suite\n",
      "\n",
      "=== TEST 1: Neighbor Index Logic ===\n",
      "Test region: center=100, neighbors=[ 97  99 102 103 101  79  78  75]\n",
      "Available cells: [100, np.int64(97), np.int64(99), np.int64(102), np.int64(103), np.int64(101), np.int64(79), np.int64(78), np.int64(75)]\n",
      "Generated 9 patches\n",
      "✅ Neighbor index logic test passed!\n",
      "\n",
      "=== TEST 2: Boundary Padding ===\n",
      "Patch 0: center=1000, padding=7/8 neighbors\n",
      "Patch 1: center=1001, padding=7/8 neighbors\n",
      "Patch 2: center=1050, padding=8/8 neighbors\n",
      "✅ Boundary padding test passed!\n",
      "\n",
      "=== TEST 3: Stride Functionality ===\n",
      "Stride 1: 100 patches (expected ~100)\n",
      "Stride 2: 50 patches (expected ~50)\n",
      "Stride 4: 25 patches (expected ~25)\n",
      "Stride 5: 20 patches (expected ~20)\n",
      "✅ Stride functionality test passed!\n",
      "\n",
      "=== TEST 4: Forward Pass Shapes ===\n",
      "Input shape: torch.Size([2, 5, 100])\n",
      "Expected output shape: (2, 16, 100)\n",
      "Actual output shape: torch.Size([2, 16, 100])\n",
      "✅ Forward pass shapes test passed!\n",
      "\n",
      "=== TEST 5: Patch Extraction Correctness ===\n",
      "Input data: tensor([0., 1., 2., 3., 4.])\n",
      "Cell to data mapping: {np.int64(100): 0, np.int64(101): 1, np.int64(102): 2, np.int64(103): 3, np.int64(104): 4}\n",
      "Extracted patches shape: torch.Size([1, 1, 5, 9])\n",
      "First patch values: [0. 0. 0. 2. 3. 1. 0. 0. 0.]\n",
      "First patch cell IDs: [100 100 100 102 103 101 100 100 100]\n",
      "Expected data indices: [0, 0, 0, 2, 3, 1, 0, 0, 0]\n",
      "✅ Patch extraction correctness test passed!\n",
      "\n",
      "=== TEST 6: Gradient Flow ===\n",
      "Input gradient shape: torch.Size([1, 3, 50])\n",
      "Conv weight gradient shape: torch.Size([8, 3, 9])\n",
      "Input gradient norm: 21.143814\n",
      "Weight gradient norm: 86.793938\n",
      "✅ Gradient flow test passed!\n",
      "\n",
      "=== TEST 7: Memory Efficiency ===\n",
      "Input tensor size: 0.31 MB\n",
      "Output tensor size: 0.49 MB\n",
      "Number of patches: 1000\n",
      "✅ Memory efficiency test passed!\n",
      "\n",
      "==================================================\n",
      "TEST SUMMARY\n",
      "==================================================\n",
      "neighbor_index: ✅ PASSED\n",
      "boundary_padding: ✅ PASSED\n",
      "stride: ✅ PASSED\n",
      "forward_shapes: ✅ PASSED\n",
      "patch_extraction: ✅ PASSED\n",
      "gradient_flow: ✅ PASSED\n",
      "memory_efficiency: ✅ PASSED\n",
      "\n",
      "Overall: 7/7 tests passed\n",
      "🎉 ALL TESTS PASSED! The spherical convolution implementation is working correctly.\n",
      "\n",
      "============================================================\n",
      "🔍 Starting Visual and Logic Tests\n",
      "============================================================\n",
      "\n",
      "=== Step-by-Step Patch Extraction Test ===\n",
      "Test region has 52 cells\n",
      "Testing with cell: 178\n",
      "\n",
      "=== Neighbor Logic Test for Cell 178 ===\n",
      "Raw neighbors from HEALPix: [167 173 184 185 179 177 176 165]\n",
      "Final patch (center + 8 neighbors): [178, np.int64(167), np.int64(173), np.int64(184), np.int64(185), np.int64(179), np.int64(177), np.int64(176), np.int64(165)]\n",
      "Padding applied: 0/8 neighbors replaced with center\n",
      "Neighbor Analysis:\n",
      "  Neighbor 0: 167 -> AVAILABLE\n",
      "  Neighbor 1: 173 -> AVAILABLE\n",
      "  Neighbor 2: 184 -> AVAILABLE\n",
      "  Neighbor 3: 185 -> AVAILABLE\n",
      "  Neighbor 4: 179 -> AVAILABLE\n",
      "  Neighbor 5: 177 -> AVAILABLE\n",
      "  Neighbor 6: 176 -> AVAILABLE\n",
      "  Neighbor 7: 165 -> AVAILABLE\n",
      "\n",
      "Mock data shape: (52,)\n",
      "Mock data values: [  0  10  20  30  40  50  60  70  80  90 100 110 120 130 140 150 160 170\n",
      " 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350\n",
      " 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510]\n",
      "  Cell 178 -> data_idx 26 -> value 260\n",
      "  Cell 167 -> data_idx 15 -> value 150\n",
      "  Cell 173 -> data_idx 21 -> value 210\n",
      "  Cell 184 -> data_idx 32 -> value 320\n",
      "  Cell 185 -> data_idx 33 -> value 330\n",
      "  Cell 179 -> data_idx 27 -> value 270\n",
      "  Cell 177 -> data_idx 25 -> value 250\n",
      "  Cell 176 -> data_idx 24 -> value 240\n",
      "  Cell 165 -> data_idx 13 -> value 130\n",
      "Extracted patch values: [np.int64(260), np.int64(150), np.int64(210), np.int64(320), np.int64(330), np.int64(270), np.int64(250), np.int64(240), np.int64(130)]\n",
      "\n",
      "=== Convolution Mathematics Test ===\n",
      "Input data shape: torch.Size([1, 2, 20])\n",
      "Channel 0 values: [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19.]\n",
      "Channel 1 values: [ 0.  2.  4.  6.  8. 10. 12. 14. 16. 18. 20. 22. 24. 26. 28. 30. 32. 34.\n",
      " 36. 38.]\n",
      "Output shape: torch.Size([1, 1, 20])\n",
      "Output values: [ 18. 105.  96. 156. 126. 156. 156. 183. 189. 225. 240. 279. 282. 381.\n",
      " 285. 399. 438. 465. 456. 495.]\n",
      "First patch data indices: tensor([0, 0, 0, 2, 3, 1, 0, 0, 0])\n",
      "Expected sum for first patch: 18.0\n",
      "Actual output for first patch: 18.0\n",
      "✅ Convolution mathematics verified!\n",
      "\n",
      "=== Boundary Cases Test ===\n",
      "✅ Single cell region test passed\n",
      "Chain test: 3 patches created\n",
      "✅ Chain cells test passed\n",
      "Large stride test: 10 patches (expected ~10)\n",
      "✅ Large stride test passed\n",
      "\n",
      "=== Comparison with Original Implementation ===\n",
      "Full sphere test with 192 cells\n",
      "Our implementation output shape: torch.Size([1, 8, 192])\n",
      "Number of patches: 192\n",
      "✅ Full sphere comparison test passed\n",
      "\n",
      "🎉 All visual and logic tests completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W718 10:11:55.020261638 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W718 10:11:55.020915754 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W718 10:11:55.045348704 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W718 10:11:55.048977796 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from typing import List, Tuple\n",
    "\n",
    "class SphericalConvVisualTest:\n",
    "    \"\"\"Visual tests to verify the spherical convolution logic\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.level = 4  # Small level for visualization\n",
    "        self.nside = 2 ** self.level\n",
    "\n",
    "    def create_test_region(self, center_lat: float = 45.0, center_lon: float = 10.0,\n",
    "                          radius_deg: float = 20.0) -> List[int]:\n",
    "        \"\"\"Create a test region similar to your geographical area\"\"\"\n",
    "\n",
    "        # Convert center to HEALPix pixel\n",
    "        center_pix = hp.ang2pix(self.nside, center_lon, center_lat, lonlat=True, nest=True)\n",
    "\n",
    "        # Get all pixels within radius\n",
    "        vec = hp.ang2vec(center_lon, center_lat, lonlat=True)\n",
    "        pixels_in_region = hp.query_disc(self.nside, vec, np.radians(radius_deg), nest=True)\n",
    "\n",
    "        return sorted(pixels_in_region.tolist())\n",
    "\n",
    "    def visualize_neighbor_logic(self, test_cell_id: int, available_cells: List[int]):\n",
    "        \"\"\"Visualize how neighbor finding works for a specific cell\"\"\"\n",
    "\n",
    "        print(f\"\\n=== Neighbor Logic Test for Cell {test_cell_id} ===\")\n",
    "\n",
    "        # Get all neighbors using HEALPix\n",
    "        neighbors = hp.get_all_neighbours(self.nside, test_cell_id, nest=True)\n",
    "        print(f\"Raw neighbors from HEALPix: {neighbors}\")\n",
    "\n",
    "        # Apply your strategy\n",
    "        available_set = set(available_cells)\n",
    "        valid_neighbors = [\n",
    "            n if (n != -1 and n in available_set) else test_cell_id\n",
    "            for n in neighbors\n",
    "        ]\n",
    "\n",
    "        patch = [test_cell_id] + valid_neighbors\n",
    "        print(f\"Final patch (center + 8 neighbors): {patch}\")\n",
    "\n",
    "        # Count padding\n",
    "        padding_count = sum(1 for n in valid_neighbors if n == test_cell_id)\n",
    "        print(f\"Padding applied: {padding_count}/8 neighbors replaced with center\")\n",
    "\n",
    "        # Analyze neighbor availability\n",
    "        neighbor_analysis = []\n",
    "        for i, n in enumerate(neighbors):\n",
    "            if n == -1:\n",
    "                status = \"INVALID (edge of sphere)\"\n",
    "            elif n in available_set:\n",
    "                status = \"AVAILABLE\"\n",
    "            else:\n",
    "                status = \"MISSING (outside region)\"\n",
    "            neighbor_analysis.append(f\"  Neighbor {i}: {n} -> {status}\")\n",
    "\n",
    "        print(\"Neighbor Analysis:\")\n",
    "        for analysis in neighbor_analysis:\n",
    "            print(analysis)\n",
    "\n",
    "        return patch\n",
    "\n",
    "    def test_patch_extraction_step_by_step(self):\n",
    "        \"\"\"Step by step test of patch extraction\"\"\"\n",
    "\n",
    "        print(\"\\n=== Step-by-Step Patch Extraction Test ===\")\n",
    "\n",
    "        # Create small test region\n",
    "        test_region = self.create_test_region(center_lat=45.0, center_lon=10.0, radius_deg=15.0)\n",
    "        print(f\"Test region has {len(test_region)} cells\")\n",
    "\n",
    "        # Test with a specific cell\n",
    "        test_cell = test_region[len(test_region)//2]  # Middle cell\n",
    "        print(f\"Testing with cell: {test_cell}\")\n",
    "\n",
    "        # Show neighbor logic\n",
    "        patch = self.visualize_neighbor_logic(test_cell, test_region)\n",
    "\n",
    "        # Create mock data\n",
    "        cell_to_data_idx = {cell_id: i for i, cell_id in enumerate(test_region)}\n",
    "        mock_data = np.arange(len(test_region)) * 10  # Easy to identify values\n",
    "\n",
    "        print(f\"\\nMock data shape: {mock_data.shape}\")\n",
    "        print(f\"Mock data values: {mock_data}\")\n",
    "\n",
    "        # Extract patch values\n",
    "        patch_values = []\n",
    "        for cell_id in patch:\n",
    "            data_idx = cell_to_data_idx[cell_id]\n",
    "            value = mock_data[data_idx]\n",
    "            patch_values.append(value)\n",
    "            print(f\"  Cell {cell_id} -> data_idx {data_idx} -> value {value}\")\n",
    "\n",
    "        print(f\"Extracted patch values: {patch_values}\")\n",
    "\n",
    "        return patch_values\n",
    "\n",
    "    def test_convolution_mathematics(self):\n",
    "        \"\"\"Test the mathematical correctness of convolution\"\"\"\n",
    "\n",
    "        print(\"\\n=== Convolution Mathematics Test ===\")\n",
    "\n",
    "        # Create simple test case\n",
    "        test_region = list(range(100, 120))  # 20 cells\n",
    "        n_channels = 2\n",
    "\n",
    "\n",
    "        conv_layer = RegionalSphericalConv(\n",
    "            available_cell_ids=test_region,\n",
    "            level=self.level,\n",
    "            in_channels=n_channels,\n",
    "            out_channels=1,  # Single output for easier verification\n",
    "            stride=1\n",
    "        )\n",
    "\n",
    "        # Create simple input where each cell has its index as value\n",
    "        input_data = torch.zeros(1, n_channels, len(test_region))\n",
    "        for i in range(len(test_region)):\n",
    "            input_data[0, 0, i] = i  # Channel 0: cell index\n",
    "            input_data[0, 1, i] = i * 2  # Channel 1: 2x cell index\n",
    "\n",
    "        print(f\"Input data shape: {input_data.shape}\")\n",
    "        print(f\"Channel 0 values: {input_data[0, 0, :].numpy()}\")\n",
    "        print(f\"Channel 1 values: {input_data[0, 1, :].numpy()}\")\n",
    "\n",
    "        # Manually set conv weights for predictable output\n",
    "        with torch.no_grad():\n",
    "            # Set weight to sum all inputs in a patch\n",
    "            conv_layer.conv.weight.fill_(1.0)  # All weights = 1\n",
    "            if conv_layer.conv.bias is not None:\n",
    "                conv_layer.conv.bias.fill_(0.0)  # No bias\n",
    "\n",
    "        # Forward pass\n",
    "        output = conv_layer(input_data)\n",
    "        print(f\"Output shape: {output.shape}\")\n",
    "        print(f\"Output values: {output[0, 0, :].detach().numpy()}\")\n",
    "\n",
    "        # Verify first patch manually\n",
    "        first_patch_indices = conv_layer.data_neighbor_indices[0]\n",
    "        print(f\"First patch data indices: {first_patch_indices}\")\n",
    "\n",
    "        # Calculate expected output for first patch\n",
    "        expected_sum = 0\n",
    "        for channel in range(n_channels):\n",
    "            for idx in first_patch_indices:\n",
    "                expected_sum += input_data[0, channel, idx].item()\n",
    "\n",
    "        actual_output = output[0, 0, 0].item()\n",
    "        print(f\"Expected sum for first patch: {expected_sum}\")\n",
    "        print(f\"Actual output for first patch: {actual_output}\")\n",
    "\n",
    "        # They should match (within floating point precision)\n",
    "        assert abs(expected_sum - actual_output) < 1e-5, \\\n",
    "            f\"Mathematics error: expected {expected_sum}, got {actual_output}\"\n",
    "\n",
    "        print(\"✅ Convolution mathematics verified!\")\n",
    "\n",
    "    def test_boundary_cases(self):\n",
    "        \"\"\"Test edge cases and boundary conditions\"\"\"\n",
    "\n",
    "        print(\"\\n=== Boundary Cases Test ===\")\n",
    "\n",
    "        # Test 1: Single cell region\n",
    "        single_cell = [1000]\n",
    "        try:\n",
    "            conv_single = RegionalSphericalConv(\n",
    "                available_cell_ids=single_cell,\n",
    "                level=self.level,\n",
    "                in_channels=1,\n",
    "                out_channels=4,\n",
    "                stride=1\n",
    "            )\n",
    "\n",
    "            # All neighbors should be the center cell\n",
    "            patch = conv_single.neighbor_indices[0]\n",
    "            assert all(cell == 1000 for cell in patch), \"Single cell test failed\"\n",
    "            print(\"✅ Single cell region test passed\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Single cell test failed: {e}\")\n",
    "\n",
    "        # Test 2: Linear chain of cells\n",
    "        chain_cells = [2000, 2001, 2002]  # Sparse chain\n",
    "        try:\n",
    "            conv_chain = RegionalSphericalConv(\n",
    "                available_cell_ids=chain_cells,\n",
    "                level=self.level,\n",
    "                in_channels=1,\n",
    "                out_channels=4,\n",
    "                stride=1\n",
    "            )\n",
    "\n",
    "            print(f\"Chain test: {conv_chain.n_patches} patches created\")\n",
    "\n",
    "            # Check that patches are valid\n",
    "            for i, patch in enumerate(conv_chain.neighbor_indices):\n",
    "                assert all(cell in chain_cells for cell in patch), \\\n",
    "                    f\"Invalid cell in chain patch {i}\"\n",
    "\n",
    "            print(\"✅ Chain cells test passed\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Chain cells test failed: {e}\")\n",
    "\n",
    "        # Test 3: Very large stride\n",
    "        large_region = list(range(3000, 3100))  # 100 cells\n",
    "        try:\n",
    "            conv_large_stride = RegionalSphericalConv(\n",
    "                available_cell_ids=large_region,\n",
    "                level=self.level,\n",
    "                in_channels=1,\n",
    "                out_channels=4,\n",
    "                stride=10\n",
    "            )\n",
    "\n",
    "            expected_patches = len(large_region) // 10\n",
    "            actual_patches = conv_large_stride.n_patches\n",
    "\n",
    "            print(f\"Large stride test: {actual_patches} patches (expected ~{expected_patches})\")\n",
    "            assert abs(actual_patches - expected_patches) <= 1, \"Large stride test failed\"\n",
    "            print(\"✅ Large stride test passed\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Large stride test failed: {e}\")\n",
    "\n",
    "    def compare_with_original_implementation(self):\n",
    "        \"\"\"Compare behavior with the original spherical conv when possible\"\"\"\n",
    "\n",
    "        print(\"\\n=== Comparison with Original Implementation ===\")\n",
    "\n",
    "        # For this test, we'll create a full sphere region to compare\n",
    "        # This simulates what the original implementation expects\n",
    "\n",
    "        level = 2  # Very small for full sphere test\n",
    "        nside = 2 ** level\n",
    "        all_cells = list(range(hp.nside2npix(nside)))\n",
    "\n",
    "        print(f\"Full sphere test with {len(all_cells)} cells\")\n",
    "\n",
    "        # Create our regional implementation with full sphere\n",
    "        our_conv = RegionalSphericalConv(\n",
    "            available_cell_ids=all_cells,\n",
    "            level=level,\n",
    "            in_channels=3,\n",
    "            out_channels=8,\n",
    "            stride=1\n",
    "        )\n",
    "\n",
    "        # Create test input\n",
    "        input_tensor = torch.randn(1, 3, len(all_cells))\n",
    "\n",
    "        # Forward pass\n",
    "        our_output = our_conv(input_tensor)\n",
    "\n",
    "        print(f\"Our implementation output shape: {our_output.shape}\")\n",
    "        print(f\"Number of patches: {our_conv.n_patches}\")\n",
    "\n",
    "        # Basic sanity checks\n",
    "        assert our_output.shape[0] == 1, \"Batch dimension wrong\"\n",
    "        assert our_output.shape[1] == 8, \"Channel dimension wrong\"\n",
    "        assert our_output.shape[2] == len(all_cells), \"Should have one patch per cell for full sphere\"\n",
    "\n",
    "        print(\"✅ Full sphere comparison test passed\")\n",
    "\n",
    "    def run_all_visual_tests(self):\n",
    "        \"\"\"Run all visual and logic tests\"\"\"\n",
    "\n",
    "        print(\"🔍 Starting Visual and Logic Tests\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        try:\n",
    "            self.test_patch_extraction_step_by_step()\n",
    "            self.test_convolution_mathematics()\n",
    "            self.test_boundary_cases()\n",
    "            self.compare_with_original_implementation()\n",
    "\n",
    "            print(\"\\n🎉 All visual and logic tests completed successfully!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Visual test failed: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "# Run the comprehensive test suite first\n",
    "print(\"Running comprehensive test suite...\")\n",
    "test_suite = SphericalConvTestSuite()\n",
    "test_suite.run_all_tests()\n",
    "\n",
    "# Then run visual tests\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "visual_test = SphericalConvVisualTest()\n",
    "visual_test.run_all_visual_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47225be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eopf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
